{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#who-we-are","title":"Who we are","text":"<p>The Microbial Ecology Group (MEG) is an interdisciplinary group of scientists from multiple institutions that conduct collaborative research addressing the issues of microbial ecology in animal, public, and environmental health. Lead scientists for MEG hail from (alphabetically): Colorado State University, Texas A&amp;M University, University of Florida, University of Minnesota, and West Texas A&amp;M University.</p>"},{"location":"#what-we-do","title":"What we do","text":"<p>Microbial ecology\u00a0is the study of diversity, distribution, and abundance of microorganisms, their interactions with each other and the biotic and abiotic features of their environments, and the effects that they have on ecosystems1. It is increasingly recognized that  health states are affected by complex interactions within microbial communities (the microbiome) and between the microbiome and hosts can have dramatic impacts on health and disease.</p> <p>MEG team members are experts in agricultural and food production systems, veterinary medicine, public health, molecular biology, microbiology and food safety, host genomics, ecosystem health, epidemiology, computational biology, bioinformatics, and advanced statistics. The MEG team integrate their unique talents and expertise to collaborative address the critically important research regarding antimicrobial resistance, microbial ecology, host-microbe interactions, and infectious disease pathogenesis as these affect animals, public health, and ecosystem health.</p>"},{"location":"#open-science-sharing-your-research-with-the-world","title":"Open Science - Sharing Your Research with the World:","text":"<p>MEG embraces the philosophy of open science to promote transparency, and improve repeatability and efficiency in research. In line with this principle, we are sharing the tools that we have developed through our research to facilitate metagenomic investigations of antimicrobial resistance using genomic sequencing and high-throughput computational analysis.</p>"},{"location":"#megares","title":"MEGARes","text":"<p>The MEGARes V3.0 database contains sequence data for nearly 9,000 hand-curated antimicrobial resistance genes accompanied by an annotation structure that is optimized for use with high throughput sequencing. The acyclical annotation graph of MEGARes allows for accurate, count-based, hierarchical statistical analysis of resistance at the population level, much like microbiome analysis, and is also designed to be used as a training database for the creation of statistical classifiers.</p>"},{"location":"#amr-pipeline","title":"AMR++ Pipeline","text":"<p>AMR++ is a bioinformatic pipeline meant to aid in the analysis of raw sequencing reads to  characterize the profile of antimicrobial resistance genes, or resistome. AMR++ was developed to work in conjuction with the the MEGARes database and its accompanying acyclical annotation structure that is optimized for use with high throughput sequencing and metagenomic analysis.  AMR++ V3.0 adds a new feature for high-throughput verification of resistance-conferring SNPs in relevant gene accessions (ARGs).</p> <ol> <li> <p>Gray, N. D. &amp; Head, I. M. in Encyclopedia of Ecology (eds S.E. Jorgensen &amp; B.D. Fath) 2357-2368 (Elsevier Science, 2008).\u00a0\u21a9</p> </li> </ol>"},{"location":"amrplusplus/","title":"AMR++ Bioinformatic Pipeline","text":"<p>AMR++ is a bioinformatic pipeline meant to aid in the high-throughput analysis of raw metagenomic sequencing reads to characterize the profile of antimicrobial resistance genes, or resistome. AMR++ was developed to work in conjuction with the the MEGARes database and the accompanying annotation structure that is optimized for use with high throughput analysis of metagenomic sequencing data. The acyclical annotation graph of MEGARes allows for accurate, count-based, hierarchical statistical analysis of resistance at the population level, much like microbiome analysis, and is also designed to be used as a training database for the creation of statistical classifiers.</p> <p>MEGARes 3.0 contains sequence data for nearly 9,000 hand-curated antimicrobial resistance genes, and AMR++ v3.0 adds a new feature for high-throughput verification of resistance-conferring SNPs in relevant gene accessions (ARGs). </p> <p>The goal of many metagenomics studies is to characterize the content and relative abundance of sequences of interest from the DNA of a given sample or set of samples. You may want to know what is contained within your sample or how abundant a given sequence is relative to another.</p> <p>Often, metagenomic analyses are performed when the answer to these questions must be obtained for a large number of targets where techniques like multiplex PCR and other targeted methods would be too cumbersome to perform. AMR++ can process the raw data from the sequencer, identify the fragments of DNA, and count them. It also provides a count of the polymorphisms that occur in each DNA fragment with respect to the reference database.</p>"},{"location":"amrplusplus/#features","title":"Features","text":"<ul> <li>With AMR++, you will obtain alignment count files for each sample that are combined into a count matrix that can be analyzed using any statistical and mathematical techniques that can operate on a matrix of observations.</li> <li>Additionally, you may want to know if the depth of your sequencing (how many reads you obtain that are on target) is high enough to identify rare organisms (organisms with low abundance relative to others) in your population. This is referred to as rarefaction and is calculated by randomly subsampling your sequence data at intervals between 0% and 100% in order to determine how many targets are found at each depth and plotting the results at each taxa level (class, mechanism, group, etc).</li> <li>New Features</li> <li>AMR++ works in conjuction with AmrPlusPlus_SNP to provide SNP verification for gene accessions requiring certain SNPs to confer resistance.</li> <li>AMR++ is primarily developed in the nextflow programming language, but as another option to users, we now also provide AMR++ as a SnakeMake pipeline.</li> </ul>"},{"location":"amrplusplus/latest/FAQs/","title":"FAQ","text":""},{"location":"amrplusplus/latest/FAQs/#troubleshooting-and-frequently-asked-questions-faqs","title":"Troubleshooting and frequently asked questions (FAQs)","text":"<p>Many errors that may be encountered may ultimately be the result of user error. If you encounter an error message any time that this pipeline is used, carefully check the command you used for any spelling errors. Additionally, many of these error messages give some detail as too where the code is wrong. Here are a few common errors and our suggestions for basic troubleshooting.</p> <ul> <li>Are you using the correct \"profile\" to run AmrPlusPlus?</li> <li> <p>We provide many examples of profile configurationg and choosing the correct one depends on your computing environment.</p> <ul> <li>If you have singularity installed on your server, we recommend using the \"singularity\" profile to avoid the installation of any additional tools. </li> <li>If you already have the tools installed on your server, the best option is to configure the local.config file to point to the absolute PATH to each too.</li> </ul> </li> <li> <p>Are the right user permissions are granted to the file/directory/server in which you are going to run the pipeline?</p> </li> <li>In servers with multiple users, there are often cases in which certain directories give some users more editing privileges than others. Start by navigating to the directory in which you will be working. Next, type \u201cls -lha or ls -l\u201d. This produces a list of all files in that directory and info on what permissions the user has using the \u201c-rwxrwxrwx\u201d scheme; r = read permissions, w = writing permissions, and x = execute permissions).</li> <li>Permission errors could be due to the directories chosen for the pipeline output or individual bioinformatic tools installed by other users, for example. </li> <li>Review this tutorial for more information regarding file permissions: https://www.guru99.com/file-permissions.html</li> </ul>"},{"location":"amrplusplus/latest/citing/","title":"Citation for MEGARes 3.0 and AMR++ 3.0:","text":"<p>In review - To be determined </p>"},{"location":"amrplusplus/latest/configuration/","title":"Contents","text":"<ul> <li>Configuration</li> <li>Customize environmental variables using profiles</li> <li>Customize parameters using the commandline</li> <li>Modifying the params.config file </li> <li>Modifying parameters using the command-line<ul> <li>Analyzing your samples</li> <li>Running with Kraken</li> <li>Including SNP confirmation</li> <li>Including deduplicated count results</li> </ul> </li> <li>Selecting the right pipeline</li> </ul>"},{"location":"amrplusplus/latest/configuration/#configuration","title":"Configuration","text":"<p>The pipeline source code comes with two configuration files that can be used to set environment variables and default command-line options. These configuration files can be found in the root source code directory and are called nextflow.config and params.config.</p> <p>The nextflow.config file mainly contains parameters regarding how AMR++ will run on your computing cluster using the <code>--profile</code> parameter. </p> <p>The params.config contains parameters that control which files are being analyzed and parameters for the software in the pipeline. Setting the variables in the params.config before hand may be useful in situations when you do not want to specify a long list of options from the command line or want to have a seperate file for each project. You can modify these files, save the changes, and run the pipeline directly. More details below.</p>"},{"location":"amrplusplus/latest/configuration/#customize-environment-variables-using-profiles","title":"Customize Environment Variables using profiles","text":"<p>The nextflow.config contains a section that allows the use of environment \"profiles\" when running AmrPlusPlus. Further information for each profile can be found within the /config directory. In brief, profiles allow control over how the pipeline is run on different computing clusters. We recommend the \"singularity\" profile which employs singularity containers which contain all the required bioinformatic tools.</p> <p>We make the following profiles available to suit your computing needs; \"local\", \"local_slurm\", \"conda\",\"conda_slurm\", \"singularity\", \"singularity_slurm\", and \"docker\". You specify which profile to use with the <code>`-profile</code> flag.</p> <pre><code>profiles {\nlocal {\nincludeConfig \"config/local.config\"\n}\nlocal_slurm {\nincludeConfig \"config/local_slurm.config\"\nprocess.executor = 'slurm'\n}\nconda {\nincludeConfig \"config/conda.config\"\nconda.enabled = true\nconda.cacheDir = \"$baseDir/envs/\"\nconda.useMamba = true\nconda.createTimeout = '30 min'\n}\ndocker {\nincludeConfig \"config/local.config\"\ndocker.enabled = true\nprocess.container = 'enriquedoster/amrplusplus:latest'\n}\nsingularity {\nincludeConfig \"config/singularity.config\"\nsingularity.enabled = true\nsingularity.autoMounts = true\nsingularity.cacheDir = \"$baseDir/envs/\"\n}\nconda_slurm {\nincludeConfig \"config/conda_slurm.config\"\nprocess.executor = 'slurm'\nconda.cacheDir = \"$baseDir/envs/\"\nconda.enabled = true\nconda.useMamba = true\nconda.createTimeout = '30 min'\n}\nsingularity_slurm {\nincludeConfig \"config/singularity_slurm.config\"\nprocess.executor = 'slurm'\nsingularity.enabled = true\nsingularity.autoMounts = true\nsingularity.cacheDir = \"$baseDir/envs/\"\n}\n}\n</code></pre>"},{"location":"amrplusplus/latest/configuration/#customize-amr-pipeline-parameters","title":"Customize AMR++ pipeline parameters","text":"<p>The params section allows you to set the different commmand-line options that can be used within the pipeline. Here, you can specify input/output options, trimming options, and algorithm options.</p>"},{"location":"amrplusplus/latest/configuration/#modifying-the-paramsconfig-file","title":"Modifying the params.config file","text":"<p>Below is a list of all of the parameters that AMR++ uses by default. They can be found in the <code>params.config</code> file in the main directory. These parameters can be modified by changing this file or specifying any of these parameters on the command line using a double dash, like this: <code>--reads \"path/to/your/reads/*_R{1,2}.fastq.gz\"</code>. Otherwise, change the parameters in the <code>params.config</code> file prior to running the AMR++ pipeline.</p> <p>These are all of the parameters used by AMR++: <pre><code>params {\n/* Location of forward and reverse read pairs */\n    reads = \"${baseDir}/data/raw/*_R{1,2}.fastq.gz\"\n\n/* Location of reference/host genome */\n    reference = \"${baseDir}/data/host/chr21.fasta.gz\"\n\n/* Output directory */\n    output = \"test_results\"\n\n/* Kraken database location, default is \"null\" */   kraken_db = null\n\n    /* Location of amr index files */\n    amr_index = \"\"\n\n/* Location of antimicrobial resistance (MEGARes) database */\n    amr = \"${baseDir}/data/amr/megares_database_v3.00.fasta\"\n\n/* Location of amr annotation file */\n    annotation = \"${baseDir}/data/amr/megares_annotations_v3.00.csv\"\n\n/* Location of SNP confirmation script */\n    snp_confirmation = \"${baseDir}/bin/snp_confirmation.py\"\n\n/* Number of threads */\n    threads = 4\n\n/* Trimmomatic trimming parameters */\n    adapters = \"${baseDir}/data/adapters/nextera.fa\"\n\nleading = 3\ntrailing = 3\nslidingwindow = \"4:15\"\nminlen = 36\n\n/* Resistome threshold */\n    threshold = 10\n\n/* Starting rarefaction level */\n    min = 5\n\n/* Ending rarefaction level */\n    max = 100\n\n/* Number of levels to skip */\n    skip = 5\n\n/* Number of iterations to sample at */\n    samples = 1\n\n/* multiQC */\n    multiqc = \"$baseDir/data/multiqc\"\n\n/* Display help message */\n    help = false\n}\n</code></pre></p>"},{"location":"amrplusplus/latest/configuration/#modifying-parameters-using-the-command-line","title":"Modifying parameters using the command-line","text":""},{"location":"amrplusplus/latest/configuration/#analyzing-your-samples","title":"Analyzing your samples","text":"<p>If you intend to run multiple samples in parallel, you must specify a glob pattern for your sequence data as shown for the reads parameter. For more information on globs, please see this related article.</p> <p>For example, the default parameters can be used to run the pipeline with this command:</p> <pre><code>nextflow run main_AMR++.nf -profile singularity\n</code></pre> <p>This will run the default samples through the pipeline and this can be seen below, under the <code>--reads</code> parameter. To change the reads that were analyzed, you should specify the <code>`--reads</code> parameter on the command line. Here, we can use regular expressions to point to your samples in a different directory.</p> <pre><code>nextflow run main_AMR++.nf -profile singularity  --reads \"path/to/your/reads/*_R{1,2}.fastq.gz\" </code></pre>"},{"location":"amrplusplus/latest/configuration/#running-with-kraken","title":"Running with Kraken","text":"<p>By default, the pipeline uses the default minikraken database (~4GB) to classify and assign taxonomic labels to your sequences. As Kraken loads this database into memory, this mini database is particularly useful for people who do not have access to large memory servers. We provide a script to easily download the minikraken database.</p> <pre><code> sh download_minikraken.sh\n ```\n\nIf you would like to use a custom database or the standard Kraken database (~160GB), you will need to build it yourself and modify the **kraken_db** environment variable in the ```params.config ``` file to point to its location on your machine. #### Running with SNP confirmation\n-----\nTo include SNP confirmation as part of the AMR++ analysis, you have to include the ```--snp Y``` flag. Like this:\n\n```bash\nnextflow run main_AMR++.nf -profile singularity  --reads \"path/to/your/reads/*_R{1,2}.fastq.gz\" --snp Y\n</code></pre>"},{"location":"amrplusplus/latest/configuration/#running-with-deduplicated-counts","title":"Running with deduplicated counts","text":"<p>Additionally, you can also output deduplicated counts by cinluding the flag, <code>--deduped Y</code>. Like this:</p> <pre><code>nextflow run main_AMR++.nf -profile singularity  --reads \"path/to/your/reads/*_R{1,2}.fastq.gz\" --snp Y --deduped Y\n</code></pre>"},{"location":"amrplusplus/latest/configuration/#selecting-the-right-pipeline","title":"Selecting the right pipeline","text":"<p>AMR++ now includes the option to run different components of the pipeline at a time by specifying the <code>--pipeline</code> flag.</p> <p>Main pipeline options   * Standard AMR pipeline ( QC trimming &gt; Host DNA removal &gt; Resistome alignment &gt; Resistome results)     <pre><code>--pipeline standard_AMR\n</code></pre>   * Fast AMR pipeline (QC trimming &gt; Resistome alignment &gt; Resistome results)     <pre><code>--pipeline fast_AMR\n</code></pre>   * AMR pipeline with kraken ( QC trimming &gt; Host DNA removal &gt; Resistome alignment &gt; Resistome results) &amp; (Non-host reads &gt; Microbiome analysis)     <pre><code>--pipeline standard_AMR_wKraken\n</code></pre>   * 16S Microbiome analysis with qiime2 (DADA2 QC &gt; Classification with SILVA)     <pre><code>--pipeline qiime2\n</code></pre> Pipeline components   * Evaluate QC with multiQC     <pre><code>--pipeline eval_qc\n</code></pre>   * QC trimming with trimmomatic     <pre><code>--pipeline trim_qc\n</code></pre>   * Align reads to host DNA and remove contaminants     <pre><code>--pipeline rm_host\n</code></pre>   * Only perform AMR++ resistome analysis     <pre><code>--pipeline resistome\n</code></pre>   * Only perform microbiome analysis with Kraken     <pre><code>--pipeline kraken\n</code></pre></p>"},{"location":"amrplusplus/latest/contact/","title":"Contact","text":""},{"location":"amrplusplus/latest/contact/#contact","title":"Contact","text":"<p>Questions, comments, or feature requests can be directed to meglab.metagenomics@gmail.com.</p> <p>View our website for further information: http://meglab.org/</p>"},{"location":"amrplusplus/latest/dependencies/","title":"Dependencies","text":""},{"location":"amrplusplus/latest/dependencies/#dependencies","title":"Dependencies","text":"<p>AMR++ uses a variety of open-source tools. The tools used, descriptions, and version specifics are provided below. These dependencies can be installed manually to your local computing cluster, or by changing the <code>-profile</code> parameter, they can be handled using conda, sigularity, or docker.</p>"},{"location":"amrplusplus/latest/dependencies/#trimmomatic","title":"Trimmomatic","text":"<ul> <li>Description: Trimmomatic is a tool for removing low quality base pairs (bps) and adapter sequences from raw sequence data.</li> <li>Version: 0.39</li> <li>DOI: https://doi.org/10.1093/bioinformatics/btu170</li> </ul>"},{"location":"amrplusplus/latest/dependencies/#fastqc","title":"FastQC","text":"<ul> <li>Description: A quality control tool for high throughput sequence data.</li> <li>Version: 0.11.8</li> </ul>"},{"location":"amrplusplus/latest/dependencies/#multiqc","title":"multiQC","text":"<ul> <li>Description: Create aggregate bioinformatics analysis reports across many samples and tools</li> <li>Version: 1.6</li> <li>DOI: https://doi.org/10.1093/bioinformatics/btw354</li> </ul>"},{"location":"amrplusplus/latest/dependencies/#bedtools","title":"Bedtools","text":"<ul> <li>Description: Bedtools is a suite of tools that can be used to compute and extract useful information from BAM, BED, and BCF files.</li> <li>Version: 2.28.0</li> <li>DOI: https://doi.org/10.1093/bioinformatics/btq033</li> </ul>"},{"location":"amrplusplus/latest/dependencies/#bwa","title":"BWA","text":"<ul> <li>Description: BWA is a short and long read sequence aligner for aligning raw sequence data to a reference genome.</li> <li>Version: 0.7.17</li> <li>DOI: https://doi.org/10.1093/bioinformatics/btp324</li> </ul>"},{"location":"amrplusplus/latest/dependencies/#kraken2","title":"Kraken2","text":"<ul> <li>Description: Kraken is a fast taxonomic sequence classifier that assigns taxonomy labels to short-reads.</li> <li>Version: 2.0.8</li> <li>DOI: https://doi.org/10.1186/gb-2014-15-3-r46</li> </ul>"},{"location":"amrplusplus/latest/dependencies/#rarefactionanalyzer","title":"RarefactionAnalyzer","text":"<ul> <li>Description: RarefactionAnalyzer is a tool that can be used for performing rarefaction analysis.</li> <li>Version: 0.0.0</li> <li>DOI: https://doi.org/10.1093/nar/gkw1009</li> </ul>"},{"location":"amrplusplus/latest/dependencies/#resistomeanalyzer","title":"ResistomeAnalyzer","text":"<ul> <li>Description: ResistomeAnalyzer is a tool for analyzing the resistome of large metagenomic datasets.</li> <li>Version: 0.0.0</li> <li>DOI: https://doi.org/10.1093/nar/gkw1009</li> </ul>"},{"location":"amrplusplus/latest/dependencies/#samtools","title":"Samtools","text":"<ul> <li>Description: Samtools is a program for manipulating and extracting useful information from alignment files in SAM or BAM format.</li> <li>Version: 1.9</li> <li>DOI: https://doi.org/10.1093/bioinformatics/btp352</li> </ul>"},{"location":"amrplusplus/latest/dependencies/#amrplusplus_snp","title":"AmrPlusPlus_SNP","text":"<ul> <li>Description: The AMRPlusPlus_SNP repository contains multiple progams used to either extract SNP info or to verify ARGs for resistant-conferring SNPs. </li> <li>Version: 0.0.0</li> <li>DOI: </li> </ul>"},{"location":"amrplusplus/latest/dependencies/#optional-software","title":"Optional software","text":""},{"location":"amrplusplus/latest/dependencies/#bracken","title":"Bracken","text":"<ul> <li>Description: Bracken (Bayesian Reestimation of Abundance with KrakEN) is a highly accurate statistical method that computes the abundance of species in DNA sequences from a metagenomics sample.</li> <li>Version: 2.7</li> <li>DOI: 10.7717/peerj-cs.104</li> </ul>"},{"location":"amrplusplus/latest/dependencies/#krona","title":"Krona","text":"<ul> <li>Description: Krona Tools is a set of scripts to create Krona charts from several Bioinformatics tools as well as from text and XML files.</li> <li>Version: 2.8.1</li> <li>DOI: https://doi.org/10.1186/1471-2105-12-385</li> </ul>"},{"location":"amrplusplus/latest/gettingstarted/","title":"Getting Started","text":""},{"location":"amrplusplus/latest/gettingstarted/#getting-started-with-amr","title":"Getting started with AMR++","text":"<p>To get started, view the Installation document to determine the best way to install AMR++ to your computing cluster.</p> <p>Next, we will run a small sample dataset that comes with the pipeline source code. As such, we will not be specifying any input paths as they have already been included. In this example, we'll assume Singularity is available in your computing environment.</p> <p>During the execution of AMR++, the required tool dependencies will be accessed using a Singularity container. As there are many tool dependencies, downloading the container could take some time depending on your connection speed.</p> <pre><code># If you followed the instructions on the installation document, you must now navigate to the AMR++ directory\ncd AMRplusplus\n\n# Run test of AMR++ by specifying the \"-profile singularity\".\nnextflow run main_AMR++.nf -profile singularity\n\n# Explore the \"test_results/\" directory to view pipeline outputs\nls test_results/\n</code></pre> <p>We can now change the \"--pipeline\" parameter to perform a different set of analyses. View the configuration doc for more details on pipeline options and modifying further parameters. </p> <pre><code># Run another test, but now we add \"--pipeline eval_qc\" to only calculate QC stats.\n# We'll also change the \"--output\" flag to store the results in a new directory.\nnextflow run main_AMR++.nf -profile singularity --pipeline eval_qc --output test_QC_stats\n\n# View the results\nls test_QC_stats/\n\n# Look at the multiqc_report.html and modify the params.config file to change trimming parameters.\n\n# Now, you can run just the QC trimming step with trimmomatic, by using the \"--pipeline trim_qc\" flag. Change output and work directory.\nnextflow run main_AMR++.nf -profile singularity --pipeline trim_qc --output test_QC_trimming -w work_trim\n\n# If the pipeline completes without issue, remember to erase your \"work\" directories to save storage space.\n</code></pre> <p>Alternatively, you can run the entire pipeline as shown below.</p> <pre><code># You can use the \"--pipeline standard_AMR\" to run the standard AMR++ pipeline.\nnextflow run main_AMR++.nf -profile singularity --pipeline standard_AMR --output test_AMR++_output -w work_AMR++\n</code></pre>"},{"location":"amrplusplus/latest/installation/","title":"Installation overview","text":"<p>This section will help you get started with running the AMR++ pipeline. This tutorial assumes you will be running the pipeline from a POSIX compatible system such as Linux, Solaris, or OS X.</p> <p>There are four main ways that you can install and run AMR++, based on what is easiest for your computing cluster and whether conda, singularity, or docker is already installed. </p> <p>Usually, you'll have to install nextflow, unless it's available to be loaded as module in your HPC. * Install Nextflow</p> <p>To make all of the bioinformatic tool dependencies available for use with AMR++, we have a few options: * Run AMR++ with Anaconda     * Install miniconda without \"sudo\" permissions * Run AMR++ with Singularity * Run AMR++ with Docker * Run AMR++ with locally installed tools</p>"},{"location":"amrplusplus/latest/installation/#installing-nextflow","title":"Installing nextflow","text":"<pre><code># username and host address\n$ ssh [USER]@[HOST]\n\n# Check if you have nextflow installed,\n$ nextflow -h\n\n# If not available, install Nextflow\n$ curl -s https://get.nextflow.io | bash\n# If you do not have curl installed, try wget\n# $ wget -qO- https://get.nextflow.io | bash\n\n# give write permissions to user\nchmod u+x nextflow\n\n# move nextflow executable to a folder in your $PATH environment variable. For example:\nmv nextflow $HOME/bin\n</code></pre>"},{"location":"amrplusplus/latest/installation/#run-amr-with-anaconda","title":"Run AMR++ with anaconda","text":"<p>Requirements: * Nextflow * Anaconda</p> <p>If anaconda is already installed and nextflow is working, we'll just need to download the AMR++ github repository.</p> <pre><code># Download AMR++ repository\ngit clone https://github.com/Microbial-Ecology-Group/AMRplusplus.git\n\n# Navigate into direcotry\ncd AMRplusplus\n\n# Test AMR++ by specifying the \"conda\" profile. If your computing cluster uses the slurm scheduler, use the \"conda_slurm\" profile.\nnextflow run main_AMR++.nf -profile conda\n</code></pre>"},{"location":"amrplusplus/latest/installation/#installing-miniconda-without-sudo-permissions","title":"Installing miniconda without \"sudo\" permissions.","text":"<p>We will go over a typical pipeline setup scenario in which you connect to a remote server, install miniconda (or use a local installation of anaconda), and download the pipeline source code. In cases where the Anaconda installation on your computing cluster is not updated or you are experiencing errors while installing packages, we recommend miniconda. Use this site for further information on installing miniconda on a user-writable directory. </p> <pre><code># Download miniconda\nwget https://repo.anaconda.com/miniconda/Miniconda3-py39_4.12.0-Linux-x86_64.sh\n# Run installation, follow default options. However, depending on your computing cluster when you are prompted, you should consider changing the \n# location of the installation to somewhere that is not your home directory which can have storage limits.\nbash Miniconda3-py39_4.12.0-Linux-x86_64.sh\n\n# Download AMR++ repository\ngit clone https://github.com/Microbial-Ecology-Group/AMRplusplus.git\n\n# Navigate into direcotry\ncd AMRplusplus\n\n# Test AMR++ by specifying the \"conda\" profile. If your computing cluster uses the slurm scheduler, use the \"conda_slurm\" profile.\nnextflow run main_AMR++.nf -profile conda\n</code></pre> <p>Optionally, you can create the conda environment prior to running AMR++.</p> <pre><code># If you haven't created the conda AMR++ environment as instructed above, go ahead and do that here:\nconda env create -f envs/AMR++_env.yaml\n# Now activate the conda environment\nconda activate activate AMR++_env\n\n# Now, the tools will be available \"locally\" so we must run AMR++ using the \"local\" profile.\nnextflow run main_AMR++.nf -profile local\n</code></pre>"},{"location":"amrplusplus/latest/installation/#run-amr-using-singularity","title":"Run AMR++ using Singularity","text":"<p>Requirements: * Nextflow * Singularity</p> <p>Often, HPCs will have singularity installed this will allow AMR++ to download and use a singularity container with all of the pre-installed software requirements.</p> <pre><code># Download AMR++ repository\ngit clone https://github.com/Microbial-Ecology-Group/AMRplusplus.git\n\n# Navigate into direcotry\ncd AMRplusplus\n\n# Run command with singularity profile\nnextflow run main_AMR++.nf -profile singularity\n\n# Alternatively, you can pull the singularity container first like this:\nsingularity pull docker://enriquedoster/amrplusplus:latest\n\n# Then, specify the path to the singularity image.\nnextflow run main_AMR++.nf -profile local -with-singularity amrplusplus_latest.sif\n</code></pre>"},{"location":"amrplusplus/latest/installation/#run-amr-using-docker","title":"Run AMR++ using Docker","text":"<p>Requirements: * Nextflow * Docker</p> <p>Like Singularity, Docker is another tool management option that is often available on HPCs and this can be used by AMR++ to download a docker container with all of the pre-installed software requirements.</p> <pre><code># Download AMR++ repository\ngit clone https://github.com/Microbial-Ecology-Group/AMRplusplus.git\n\n# Navigate into direcotry\ncd AMRplusplus\n\n# Run command with docker profile\nnextflow run main_AMR++.nf -profile docker\n</code></pre>"},{"location":"amrplusplus/latest/installation/#local-installation-of-tools","title":"Local installation of tools","text":"<p>Requirements: * All software requirements * Nextflow</p> <p>If Singularity cannot be installed, or perhaps your computing cluster has all of the required tools, configure the \"config/local.config\" file to specify the absolute PATH to each required bioinformatic tool. Or if you can add all of the relevant paths to your $PATH environment variable, which in some cases means loading the correct modules, then you can just leave the name of each tool without the path. Finally, change the flag after \"-profile\" to \"local\" when running the pipeline.</p> <p><code>bash nextflow run main_AMR++.nf -profile local</code></p>"},{"location":"amrplusplus/latest/output/","title":"Output","text":""},{"location":"amrplusplus/latest/output/#output","title":"Output","text":"<p>All intermediate outputs produced from each module of this pipeline are provided as flat files that can be viewed in a text editor. These files are copied from the root work/ directory created by Nextflow, so if disk space is a concern, this directory should be deleted as it can get quite large.</p>"},{"location":"amrplusplus/latest/output/#directory-structure","title":"Directory Structure","text":"<p>The output directories created by the pipeline are named after the module that produced them. Each file output is prefixed with the sample name and suffixed with a short product description. </p> <p>Files without sample prefixes are a result of aggregation. For example, the files host.removal.stats and trimmomatic.stats provide count matrices for the number of reads discarded as a result of host-dna removal and number of trimmed reads for each sample. </p> <p>Below is an example of all of the results created with a test run of AMR++.</p> <pre><code>test_results\n\u251c\u2500\u2500 Alignment\n\u2502   \u251c\u2500\u2500 BWA_Index\n\u2502   \u2502   \u251c\u2500\u2500 chr21.fasta.gz.amb\n\u2502   \u2502   \u251c\u2500\u2500 chr21.fasta.gz.ann\n\u2502   \u2502   \u251c\u2500\u2500 chr21.fasta.gz.bwt\n\u2502   \u2502   \u251c\u2500\u2500 chr21.fasta.gz.pac\n\u2502   \u2502   \u251c\u2500\u2500 chr21.fasta.gz.sa\n\u2502   \u2502   \u251c\u2500\u2500 megares_database_v3.00.fasta.amb\n\u2502   \u2502   \u251c\u2500\u2500 megares_database_v3.00.fasta.ann\n\u2502   \u2502   \u251c\u2500\u2500 megares_database_v3.00.fasta.bwt\n\u2502   \u2502   \u251c\u2500\u2500 megares_database_v3.00.fasta.pac\n\u2502   \u2502   \u2514\u2500\u2500 megares_database_v3.00.fasta.sa\n\u2502   \u2514\u2500\u2500 SAM_files\n\u2502       \u251c\u2500\u2500 Deduped\n\u2502       \u2502   \u251c\u2500\u2500 S1_test.alignment.dedup.sam\n\u2502       \u2502   \u251c\u2500\u2500 S2_test.alignment.dedup.sam\n\u2502       \u2502   \u2514\u2500\u2500 S3_test.alignment.dedup.sam\n\u2502       \u2514\u2500\u2500 Standard\n\u2502           \u251c\u2500\u2500 S1_test.alignment.sam\n\u2502           \u251c\u2500\u2500 S2_test.alignment.sam\n\u2502           \u2514\u2500\u2500 S3_test.alignment.sam\n\u251c\u2500\u2500 HostRemoval\n\u2502   \u2514\u2500\u2500 NonHostFastq\n\u2502       \u251c\u2500\u2500 S1_test.non.host.R1.fastq.gz\n\u2502       \u251c\u2500\u2500 S1_test.non.host.R2.fastq.gz\n\u2502       \u251c\u2500\u2500 S2_test.non.host.R1.fastq.gz\n\u2502       \u251c\u2500\u2500 S2_test.non.host.R2.fastq.gz\n\u2502       \u251c\u2500\u2500 S3_test.non.host.R1.fastq.gz\n\u2502       \u2514\u2500\u2500 S3_test.non.host.R2.fastq.gz\n\u251c\u2500\u2500 QC_analysis\n\u2502   \u251c\u2500\u2500 FastQC\n\u2502   \u2502   \u251c\u2500\u2500 S1_test_fastqc_logs\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 S1_test_R1_fastqc.html\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 S1_test_R1_fastqc.zip\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 S1_test_R2_fastqc.html\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 S1_test_R2_fastqc.zip\n\u2502   \u2502   \u251c\u2500\u2500 S2_test_fastqc_logs\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 S2_test_R1_fastqc.html\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 S2_test_R1_fastqc.zip\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 S2_test_R2_fastqc.html\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 S2_test_R2_fastqc.zip\n\u2502   \u2502   \u2514\u2500\u2500 S3_test_fastqc_logs\n\u2502   \u2502       \u251c\u2500\u2500 S3_test_R1_fastqc.html\n\u2502   \u2502       \u251c\u2500\u2500 S3_test_R1_fastqc.zip\n\u2502   \u2502       \u251c\u2500\u2500 S3_test_R2_fastqc.html\n\u2502   \u2502       \u2514\u2500\u2500 S3_test_R2_fastqc.zip\n\u2502   \u2514\u2500\u2500 MultiQC_stats\n\u2502       \u2514\u2500\u2500 multiqc_report.html\n\u251c\u2500\u2500 QC_trimming\n\u2502   \u251c\u2500\u2500 Paired\n\u2502   \u2502   \u251c\u2500\u2500 S1_test.1P.fastq.gz\n\u2502   \u2502   \u251c\u2500\u2500 S1_test.2P.fastq.gz\n\u2502   \u2502   \u251c\u2500\u2500 S2_test.1P.fastq.gz\n\u2502   \u2502   \u251c\u2500\u2500 S2_test.2P.fastq.gz\n\u2502   \u2502   \u251c\u2500\u2500 S3_test.1P.fastq.gz\n\u2502   \u2502   \u2514\u2500\u2500 S3_test.2P.fastq.gz\n\u2502   \u2514\u2500\u2500 Unpaired\n\u2502       \u251c\u2500\u2500 S1_test.1U.fastq.gz\n\u2502       \u251c\u2500\u2500 S1_test.2U.fastq.gz\n\u2502       \u251c\u2500\u2500 S2_test.1U.fastq.gz\n\u2502       \u251c\u2500\u2500 S2_test.2U.fastq.gz\n\u2502       \u251c\u2500\u2500 S3_test.1U.fastq.gz\n\u2502       \u2514\u2500\u2500 S3_test.2U.fastq.gz\n\u251c\u2500\u2500 ResistomeAnalysis\n\u2502   \u251c\u2500\u2500 Rarefaction\n\u2502   \u2502   \u2514\u2500\u2500 Counts\n\u2502   \u2502       \u251c\u2500\u2500 S1_test.class.tsv\n\u2502   \u2502       \u251c\u2500\u2500 S1_test.gene.tsv\n\u2502   \u2502       \u251c\u2500\u2500 S1_test.group.tsv\n\u2502   \u2502       \u251c\u2500\u2500 S1_test.mech.tsv\n\u2502   \u2502       \u251c\u2500\u2500 S1_test.type.tsv\n\u2502   \u2502       \u251c\u2500\u2500 S2_test.class.tsv\n\u2502   \u2502       \u251c\u2500\u2500 S2_test.gene.tsv\n\u2502   \u2502       \u251c\u2500\u2500 S2_test.group.tsv\n\u2502   \u2502       \u251c\u2500\u2500 S2_test.mech.tsv\n\u2502   \u2502       \u251c\u2500\u2500 S2_test.type.tsv\n\u2502   \u2502       \u251c\u2500\u2500 S3_test.class.tsv\n\u2502   \u2502       \u251c\u2500\u2500 S3_test.gene.tsv\n\u2502   \u2502       \u251c\u2500\u2500 S3_test.group.tsv\n\u2502   \u2502       \u251c\u2500\u2500 S3_test.mech.tsv\n\u2502   \u2502       \u2514\u2500\u2500 S3_test.type.tsv\n\u2502   \u2514\u2500\u2500 ResistomeCounts\n\u2502       \u251c\u2500\u2500 S1_test.AMR.class.tsv\n\u2502       \u251c\u2500\u2500 S1_test.AMR.gene.tsv\n\u2502       \u251c\u2500\u2500 S1_test.AMR.group.tsv\n\u2502       \u251c\u2500\u2500 S1_test.AMR.mechanism.tsv\n\u2502       \u251c\u2500\u2500 S1_test.AMR.type.tsv\n\u2502       \u251c\u2500\u2500 S1_test.dedup_AMR.class.tsv\n\u2502       \u251c\u2500\u2500 S1_test.dedup_AMR.gene.tsv\n\u2502       \u251c\u2500\u2500 S1_test.dedup_AMR.group.tsv\n\u2502       \u251c\u2500\u2500 S1_test.dedup_AMR.mechanism.tsv\n\u2502       \u251c\u2500\u2500 S1_test.dedup_AMR.type.tsv\n\u2502       \u251c\u2500\u2500 S2_test.AMR.class.tsv\n\u2502       \u251c\u2500\u2500 S2_test.AMR.gene.tsv\n\u2502       \u251c\u2500\u2500 S2_test.AMR.group.tsv\n\u2502       \u251c\u2500\u2500 S2_test.AMR.mechanism.tsv\n\u2502       \u251c\u2500\u2500 S2_test.AMR.type.tsv\n\u2502       \u251c\u2500\u2500 S2_test.dedup_AMR.class.tsv\n\u2502       \u251c\u2500\u2500 S2_test.dedup_AMR.gene.tsv\n\u2502       \u251c\u2500\u2500 S2_test.dedup_AMR.group.tsv\n\u2502       \u251c\u2500\u2500 S2_test.dedup_AMR.mechanism.tsv\n\u2502       \u251c\u2500\u2500 S2_test.dedup_AMR.type.tsv\n\u2502       \u251c\u2500\u2500 S3_test.AMR.class.tsv\n\u2502       \u251c\u2500\u2500 S3_test.AMR.gene.tsv\n\u2502       \u251c\u2500\u2500 S3_test.AMR.group.tsv\n\u2502       \u251c\u2500\u2500 S3_test.AMR.mechanism.tsv\n\u2502       \u251c\u2500\u2500 S3_test.AMR.type.tsv\n\u2502       \u251c\u2500\u2500 S3_test.dedup_AMR.class.tsv\n\u2502       \u251c\u2500\u2500 S3_test.dedup_AMR.gene.tsv\n\u2502       \u251c\u2500\u2500 S3_test.dedup_AMR.group.tsv\n\u2502       \u251c\u2500\u2500 S3_test.dedup_AMR.mechanism.tsv\n\u2502       \u2514\u2500\u2500 S3_test.dedup_AMR.type.tsv\n\u2514\u2500\u2500 Results\n    \u251c\u2500\u2500 AMR_analytic_matrix.csv\n    \u251c\u2500\u2500 SNPconfirmed_AMR_analytic_matrix.csv\n    \u251c\u2500\u2500 SNPconfirmed_dedup_AMR_analytic_matrix.csv\n    \u251c\u2500\u2500 Stats\n    \u2502   \u251c\u2500\u2500 host.removal.stats\n    \u2502   \u2514\u2500\u2500 trimmomatic.stats\n    \u2514\u2500\u2500 dedup_AMR_analytic_matrix.csv\n</code></pre>"},{"location":"amrplusplus/latest/references/","title":"References","text":"<ol> <li> <p>Bolger,A.M., Lohse,M. and Usadel,B. (2014) Trimmomatic: A flexible trimmer for Illumina Sequence Data. Bioinformatics, 10.1093/bioinformatics/btu170.</p> </li> <li> <p>Li,H. (2013) Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM. ArXiv13033997 Q-Bio.</p> </li> <li> <p>Quinlan,A.R. and Hall,I.M. (2010) BEDTools: a flexible suite of utilities for comparing genomic features. Bioinformatics, 26, 841\u2013842.</p> </li> <li> <p>Li,H., Handsaker,B., Wysoker,A., Fennell,T., Ruan,J., Homer,N., Marth,G., Abecasis,G., Durbin,R. and 1000 Genome Project Data Processing Subgroup (2009) The Sequence Alignment/Map format and SAMtools. Bioinforma. Oxf. Engl., 25, 2078\u20132079.</p> </li> <li> <p>Wood,D.E., Lu,J. and Langmead,B. (2019) Improved metagenomic analysis with Kraken 2. bioRxiv, 10.1101/762302.</p> </li> <li> <p>Nextflow programming language (https://www.nextflow.io/)</p> </li> <li> <p>Singularity: Scientific containers for mobility of compute. (https://singularity.lbl.gov/)</p> </li> <li> <p>Andrews,S. (2010) FastQC: A Quality Control tool for High Throughput Sequence Data.</p> </li> <li> <p>Ewels,P., Magnusson,M., Lundin,S. and K\u00e4ller,M. (2016) MultiQC: summarize analysis results for multiple tools and samples in a single report. Bioinformatics, 32, 3047\u20133048.</p> </li> <li> <p>Quinlan,A.R. and Hall,I.M. (2010) BEDTools: a flexible suite of utilities for comparing genomic features. Bioinformatics, 26, 841\u2013842.</p> </li> </ol>"},{"location":"amrplusplus/latest/requirements/","title":"Software Requirements","text":"<p>To run AMR++, you will need the following tool installed on your server or local machine.</p> <ul> <li>Anaconda or miniconda (Required)<ul> <li>Visit this website for further information: https://docs.anaconda.com/anaconda/install/</li> </ul> </li> </ul> <p>NOTE: If you choose not to install anaconda, you will need to download each of the required dependencies and add the executable paths to your .bashrc file to run the pipeline. A list of these dependencies can be found in the Dependencies section of this document.</p> <p>If anaconda or docker is not available to you, in addition to installing the listed bioinformatic tool dependencies, you'll need to install the following tools:</p> <ul> <li>Java 7+ (Required)</li> <li>Nextflow (Required)</li> </ul> <p>Another option is to use singularity:</p> <pre><code>singularity pull docker://enriquedoster/amrplusplus:latest\n\nnextflow run main_AMR++.nf -profile local --pipeline demo -with-singularity amrplusplus_latest.sif\n</code></pre>"},{"location":"amrplusplus/latest/usage/","title":"Usage","text":""},{"location":"amrplusplus/latest/usage/#usage","title":"Usage","text":""},{"location":"amrplusplus/latest/usage/#display-help-message","title":"Display Help Message","text":"<p>The <code>help</code> parameter displays the available options and commands. <pre><code>nextflow run main_AMR++.nf --help\n</code></pre></p>"},{"location":"amrplusplus/latest/usage/#parameter-selection","title":"Parameter selection","text":"<p>AMR++ comes with a default selection of parameters to perform a demonstration using example data provided in the \"data/\" directory. The example command below uses two types of parameters. </p> <pre><code>nextflow run main_AMR++.nf -profile singularity --pipeline demo\n</code></pre> <p>The <code>-profile</code> parameter only has a single dash (<code>-</code>), meaning it corresponds to a nextflow-speific parameter and the  <code>--pipeline</code>. Examples of parameters with one dash include <code>-profile</code>, <code>-resume</code>, and <code>-config</code>. Further details on using the profile parameter, which determines how AMR++ runs on a computing cluster, can be found in the configuration document. Below, we'll see how to change the pipeline-specific parameters which are denoted using two dashes (<code>--</code>), such as <code>--pipeline</code> and <code>--reads</code>.</p> <p>The AMR++ pipeline pulls information from various sources to determine the correct parameters for running the pipeline. AMR++ is written in nextflow and this allows for us to change how the pipeline runs in a variety of ways. This is the order in which nextflow will prioritize parameters it receives.</p> <ol> <li> <p>Parameters specified on the command line (--something value)</p> </li> <li> <p>Parameters provided using the -params-file option (params.config by default)</p> </li> <li> <p>Config file specified using the -c my_config option (e.g. config/local.config)</p> </li> <li> <p>The config file named nextflow.config in the current directory</p> </li> <li> <p>The config file named nextflow.config in the workflow project directory</p> </li> <li> <p>The config file $HOME/.nextflow/config</p> </li> <li> <p>Values defined within the pipeline script itself (e.g. main_AMR++.nf)</p> </li> </ol>"},{"location":"amrplusplus/latest/usage/#file-inputs","title":"File Inputs","text":""},{"location":"amrplusplus/latest/usage/#set-custom-sequence-data","title":"Set custom sequence data","text":"<p>The <code>reads</code> parameter accepts sequence files in standard fastq and gz format. <pre><code>$ nextflow run main_AMR++.nf --reads \"data/raw/*_R{1,2}.fastq\"\n</code></pre></p>"},{"location":"amrplusplus/latest/usage/#set-host-genome","title":"Set host genome","text":"<p>The <code>host</code> parameter accepts a fasta formatted host genome. <pre><code>$ nextflow run main_AMR++.nf --host \"data/host/chr21.fasta.gz\"\n</code></pre></p>"},{"location":"amrplusplus/latest/usage/#set-megares-resistance-database","title":"Set MEGARes resistance database","text":"<p>The <code>amr</code> parameter accepts a fasta formatted resistance database. AMR++ is made to work with MEGARes databases and has to have the corresponding <code>--annotation</code> file in csv format.</p> <pre><code>$ nextflow run main_AMR++.nf --amr \"data/amr/megares_database_v1.02.fasta\"\n</code></pre>"},{"location":"amrplusplus/latest/usage/#set-megares-annotation-database","title":"Set MEGARes annotation database","text":"<p>The <code>annotation</code> parameter accepts a csv formatted annotation database. Note, this must match the resistance database that was used above for the ResistomeAnalyzer and RarefactionAnalyzer steps to work correctly. </p> <pre><code>$ nextflow run main_AMR++.nf --annotation \"data/amr/megares_annotations_v1.02.csv\"\n</code></pre>"},{"location":"amrplusplus/latest/usage/#set-adapter-file","title":"Set adapter file","text":"<p>The <code>adapters</code> parameter accepts a fasta formatted adapter file. <pre><code>$ nextflow run main_AMR++.nf --adapters \"data/adapters/adapters.fa\"\n</code></pre></p>"},{"location":"amrplusplus/latest/usage/#file-outputs","title":"File Outputs","text":""},{"location":"amrplusplus/latest/usage/#set-output-and-work-directories","title":"Set output and work directories","text":"<p>The <code>--output</code> parameter writes the results to the specified directory. As a nextflow variable, the <code>-work</code> parameter only requires one dash and determines where the temporary files will be directed. Upon completing the run, you can delete the temporary file directory. <pre><code>$ nextflow run main_AMR++.nf --output \"test/\" -work \"work_dir/\"\n</code></pre></p>"},{"location":"amrplusplus/latest/usage/#resume-a-pipeline-run","title":"Resume a pipeline run","text":"<p>If the pipeline run is cancelled or stopped for whatever reason, using the same command with the addition of the <code>-resume</code> flag will attempt to pick up where the pipeline stopped. This \"work\" directory can take a lot of storage space and we recommend deleting it after completion of the pipeline.</p> <pre><code>$ nextflow run main_AMR++.nf --output \"test/\" -work \"work_dir/\" -resume\n</code></pre>"},{"location":"amrplusplus/latest/usage/#trimming-options","title":"Trimming Options","text":""},{"location":"amrplusplus/latest/usage/#set-custom-trimming-parameters-for-trimmomatic","title":"Set custom trimming parameters for trimmomatic","text":"<pre><code>$ nextflow run main_AMR++.nf \\\n    --reads \"data/raw/*_R{1,2}.fastq\" \\\n    --leading 3 \\\n    --trailing 3 \\\n    --minlen 36 \\\n    --slidingwindow 4 \\\n    --adapters \"data/adapters/nextera.fa\"\n    --output \"test/\"\n</code></pre>"},{"location":"amrplusplus/latest/usage/#algorithm-options","title":"Algorithm Options","text":""},{"location":"amrplusplus/latest/usage/#set-custom-resistomeanalyzer-algorithm-options","title":"Set custom ResistomeAnalyzer algorithm options","text":"<pre><code>$ nextflow run main_AMR++.nf \\\n    --reads \"data/raw/*_R{1,2}.fastq\" \\\n    --threshold 80 \\\n    --min 1 \\\n    --max 100 \\\n    --samples 5 \\\n    --skip 5 \\\n    --output \"test/\"\n</code></pre>"},{"location":"amrplusplus/latest/usage/#set-number-of-threads-to-use-for-each-process-when-possible","title":"Set number of threads to use for each process (when possible)","text":"<pre><code>$ nextflow run main_AMR++.nf --threads 8\n</code></pre>"},{"location":"amrplusplus/latest/usage/#run-amr-with-slurm","title":"Run AMR++ with SLURM","text":"<p>Adding the <code>-bg</code> flag submits AMR++ to the SLURM queue and when combined with a \"slurm\" profile, jobs will be submitted for each individual process in the pipeline.</p> <pre><code>nextflow run main_AMR++.nf -profile local_slurm --snp Y -bg &gt; bg-log.out\n</code></pre>"},{"location":"megares/","title":"MEGARes","text":"<p>The MEGARes V3.0 database contains sequence data for nearly 9,000 hand-curated resistance genes for antimicrobial drugs, biocides and metals, with an annotation structure that is optimized for use with high throughput sequencing. The acyclical annotation graph of MEGARes allows for accurate, count-based, hierarchical statistical analysis of resistance at the population level, much like microbiome analysis, and is also designed to be used as a training database for the creation of statistical classifiers (Figure 1).</p> <p> </p> Figure 1 <p>A.) This annotation graph contains no cycles (is a tree), as nodes 1 and 2 do not share children       and are therefore independent.       B.) In contrast, node 3 and node 4 share node 5 as a child, which creates a cycle in the annotation graph.       </p>"},{"location":"megares/#when-should-i-use-megares","title":"When should I use MEGARes?","text":"<p>For the population-level profiling or population comparison of antimicrobial resistance (count-based analyses, similar to microbiome analysis). MEGARes can also be used for the construction of sequence classifiers, e.g. naive Bayes, hidden Markov models. For users who wish to predict the protein function and functional mutations in their sequencing data, we recommend using a database suited for functional genomics, such as the Comprehensive Antibiotic Resistance Database (CARD).</p>"},{"location":"megares/#what-distinguishes-megares-from-other-databases","title":"What distinguishes MEGARes from other databases?","text":"<p>MEGARes has been designed for use in the computational analysis of large-scale sequencing data (on the order of terabytes)  in a way that is fast and accurate for statistical analyses on count-based data and the construction of sequence classifiers.  MEGARes incorporates previously published resistance gene sequences for antimicrobial drugs, biocides, and metals. Sources include Antibacterial Biocide and Metal Resistance Genes (BacMet), CARD, ResFinder and PointFinder, AMRFinderPlus. A file with links to the sources for all MEGARes gene accessions can be downloaded here.</p> <ul> <li>Sequences are annotated in a biologically meaningful way that preserves within-group nucleotide similarity.</li> <li>The annotation graph contains no cycles.  Therefore, it contains no statistical dependencies and is accurate for the count-based analyses commonly performed in population-level profiling (Figure 1).</li> <li>The annotation graph contains only three hierarchical levels, which maximizes the number of representative sequences for each annotation node.  This is designed to work well for the construction of statistical classifiers.  The annotation levels are:<ul> <li>Type: the type of antimicrobial compound, e.g. drugs, biocides, multi-compound</li> <li>Class: the major antimicrobial chemical class, e.g. betalactams, aminoglycosides</li> <li>Mechanism: the biological mechanism of resistance, e.g. penicillin binding protein</li> <li>Group: the gene- or operon-level group for that sequence, e.g. SHV betalactamase, MCR-1</li> </ul> </li> <li>All sequence metadata has been formatted to work well with the majority of bioinformatics software.  Sequence headers contain no whitespace or non-compliant symbols.</li> <li>All sequences and annotations have been hand-curated using a multi-factorial approach.  See the manuscript for more details.</li> <li>Gene accessions requiring specific single nucleotide polymorphisms (SNPS) to confer resistance include the added label \"RequiresSNPConfirmation\" in their header. This allows for easy identification for further processing. The AMR++ pipeline employs MEGARes and works in conjuction with AmrPlusPlus_SNP to perform SNP confirmation and provide an updated count matrix.</li> </ul>"},{"location":"megares/#citation-for-megares-v30-and-amr-v30","title":"Citation for MEGARes V3.0 and AMR++ V3.0:","text":"<p>Bonin N, Doster E, Worley H, Pinnell LJ, Bravo JE, Ferm P, Marini S, Prosperi M, Noyes N, Morley PS, Boucher C.</p> <p>MEGARes and AMR++, v3.0: an updated comprehensive database of antimicrobial resistance determinants and an improved software pipeline for classification using high-throughput sequencing. Nucleic Acids Res. 2022 Nov 16:gkac1047. doi: 10.1093/nar/gkac1047. Epub ahead of print. PMID: 36382407.</p> <p>PubMed</p>"},{"location":"megares/#citation-for-megares-v20-and-amr-v20","title":"Citation for MEGARes V2.0 and AMR++ V2.0:","text":"<p>Doster, E., Lakin, S. M., Dean, C. J., Wolfe, C., Young, J. G., Boucher, C., Belk K. E., Noyes N. R., Morley P. S. (2019)</p> <p>MEGARes 2.0: a database for classification of antimicrobial drug, biocide and metal resistance determinants in metagenomic sequence data. Nucleic Acids Res. doi:10.1093/nar/gkz1010.</p> <p>Click to Download Citation in different formats</p> <p>PubMed</p>"},{"location":"megares/#citation-for-megares-v10-and-amrplusplus-v10","title":"Citation for MEGARes V1.0 and AmrPlusPlus V1.0:","text":"<p>Lakin, S.M., Dean, C., Noyes, N.R., Dettenwanger, A., Spencer Ross, A., Doster, E., Rovira, P., Abdo, Z., Jones, K.L., Ruiz, J., Belk, K.E., Morley, P.S., Boucher, C. (2016)</p> <p>MEGARes: an antimicrobial database for high throughput sequencing. Nucleic Acids Res., 45. DOI: 10.1093/nar/gkw1009</p> <p>Click to Download Citation</p> <p>PubMed</p>"}]}